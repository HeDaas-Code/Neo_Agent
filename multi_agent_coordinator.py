"""
å¤šæ™ºèƒ½ä½“åä½œæ¨¡å—
å®ç°ä»»åŠ¡å‹äº‹ä»¶çš„å¤šæ™ºèƒ½ä½“åä½œå¤„ç†
"""

import os
import time
import json
from typing import List, Dict, Any, Optional, Callable
from dotenv import load_dotenv
import requests
from event_manager import TaskEvent
from interrupt_question_tool import InterruptQuestionTool
from debug_logger import get_debug_logger

load_dotenv()

# è·å–debugæ—¥å¿—è®°å½•å™¨
debug_logger = get_debug_logger()


class SubAgent:
    """
    å­æ™ºèƒ½ä½“ç±»
    ä»£è¡¨å‚ä¸åä½œçš„å•ä¸ªæ™ºèƒ½ä½“
    """

    def __init__(
        self,
        agent_id: str,
        role: str,
        description: str,
        api_key: str,
        api_url: str,
        model_name: str
    ):
        """
        åˆå§‹åŒ–å­æ™ºèƒ½ä½“

        Args:
            agent_id: æ™ºèƒ½ä½“ID
            role: æ™ºèƒ½ä½“è§’è‰²
            description: è§’è‰²æè¿°
            api_key: APIå¯†é’¥
            api_url: APIåœ°å€
            model_name: æ¨¡å‹åç§°
        """
        self.agent_id = agent_id
        self.role = role
        self.description = description
        self.api_key = api_key
        self.api_url = api_url
        self.model_name = model_name

    def execute_task(
        self,
        task_description: str,
        context: Dict[str, Any],
        tools: List[Dict[str, Any]] = None
    ) -> str:
        """
        æ‰§è¡Œä»»åŠ¡

        Args:
            task_description: ä»»åŠ¡æè¿°
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨

        Returns:
            æ‰§è¡Œç»“æœ
        """
        debug_logger.log_module('SubAgent', f'æ™ºèƒ½ä½“[{self.role}]å¼€å§‹æ‰§è¡Œä»»åŠ¡', {
            'agent_id': self.agent_id,
            'task_length': len(task_description)
        })

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ª{self.role}ã€‚

ä½ çš„èŒè´£ï¼š{self.description}

å½“å‰ä»»åŠ¡ï¼š{task_description}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{json.dumps(context, ensure_ascii=False, indent=2)}
"""

        # å¦‚æœæœ‰å¯ç”¨å·¥å…·ï¼Œæ·»åŠ å·¥å…·è¯´æ˜
        if tools:
            tools_description = "\n\nå¯ç”¨å·¥å…·ï¼š\n"
            for tool in tools:
                tools_description += f"- {tool['name']}: {tool['description']}\n"
            system_prompt += tools_description

        system_prompt += """

è¯·æŒ‰ç…§ä»»åŠ¡è¦æ±‚å®Œæˆä½ çš„å·¥ä½œï¼Œå¦‚æœ‰éœ€è¦å¯ä»¥ä½¿ç”¨å¯ç”¨çš„å·¥å…·ã€‚
è¾“å‡ºæ ¼å¼ï¼šç›´æ¥è¾“å‡ºä½ çš„å·¥ä½œç»“æœï¼Œç®€æ´æ˜äº†ã€‚"""

        # è°ƒç”¨API
        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }

            payload = {
                'model': self.model_name,
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': f'è¯·å®Œæˆä»»åŠ¡ï¼š{task_description}'}
                ],
                'temperature': 0.7,
                'max_tokens': 2000,
                'stream': False
            }

            debug_logger.log_request('SubAgent', self.api_url, payload, headers)

            start_time = time.time()
            response = requests.post(
                self.api_url,
                headers=headers,
                json=payload,
                timeout=60
            )
            elapsed_time = time.time() - start_time

            response.raise_for_status()
            result = response.json()

            debug_logger.log_response('SubAgent', result, response.status_code, elapsed_time)

            if 'choices' in result and len(result['choices']) > 0:
                output = result['choices'][0]['message']['content']
                debug_logger.log_info('SubAgent', f'æ™ºèƒ½ä½“[{self.role}]ä»»åŠ¡å®Œæˆ', {
                    'output_length': len(output),
                    'elapsed_time': elapsed_time
                })
                return output
            else:
                return "ã€æ‰§è¡Œå¤±è´¥ã€‘æœªæ”¶åˆ°æœ‰æ•ˆå“åº”"

        except Exception as e:
            debug_logger.log_error('SubAgent', f'æ™ºèƒ½ä½“[{self.role}]æ‰§è¡Œå¤±è´¥: {str(e)}', e)
            return f"ã€æ‰§è¡Œå¤±è´¥ã€‘{str(e)}"


class MultiAgentCoordinator:
    """
    å¤šæ™ºèƒ½ä½“åè°ƒå™¨
    è´Ÿè´£åè°ƒå¤šä¸ªæ™ºèƒ½ä½“å®Œæˆå¤æ‚ä»»åŠ¡
    """

    def __init__(
        self,
        question_tool: InterruptQuestionTool,
        progress_callback: Optional[Callable[[str], None]] = None
    ):
        """
        åˆå§‹åŒ–å¤šæ™ºèƒ½ä½“åè°ƒå™¨

        Args:
            question_tool: ä¸­æ–­æ€§æé—®å·¥å…·
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        """
        self.question_tool = question_tool
        self.progress_callback = progress_callback
        
        # ä»ç¯å¢ƒå˜é‡è·å–APIé…ç½®
        self.api_key = os.getenv('SILICONFLOW_API_KEY')
        self.api_url = os.getenv('SILICONFLOW_API_URL', 'https://api.siliconflow.cn/v1/chat/completions')
        self.model_name = os.getenv('MODEL_NAME', 'Qwen/Qwen2.5-7B-Instruct')
        
        debug_logger.log_module('MultiAgentCoordinator', 'å¤šæ™ºèƒ½ä½“åè°ƒå™¨åˆå§‹åŒ–å®Œæˆ')

    def emit_progress(self, message: str):
        """
        è¾“å‡ºè¿›åº¦æç¤ºï¼ˆæ—ç™½å¼ï¼‰

        Args:
            message: è¿›åº¦æ¶ˆæ¯
        """
        # æ ¼å¼åŒ–ä¸ºæ—ç™½å¼è¾“å‡º
        narration = f"ğŸ“¢ {message}"
        
        print(narration)
        
        if self.progress_callback:
            self.progress_callback(narration)
        
        debug_logger.log_info('MultiAgentCoordinator', 'è¿›åº¦æ›´æ–°', {
            'message': message
        })

    def process_task_event(
        self,
        task_event: TaskEvent,
        character_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        å¤„ç†ä»»åŠ¡å‹äº‹ä»¶

        Args:
            task_event: ä»»åŠ¡äº‹ä»¶
            character_context: è§’è‰²ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            å¤„ç†ç»“æœ
        """
        debug_logger.log_module('MultiAgentCoordinator', 'å¼€å§‹å¤„ç†ä»»åŠ¡å‹äº‹ä»¶', {
            'event_id': task_event.event_id,
            'title': task_event.title
        })

        self.emit_progress(f"æ™ºèƒ½ä½“å¼€å§‹åˆ†æä»»åŠ¡ã€Œ{task_event.title}ã€...")

        # ç¬¬ä¸€æ­¥ï¼šç†è§£ä»»åŠ¡
        task_understanding = self._understand_task(task_event, character_context)
        
        if not task_understanding.get('success'):
            return {
                'success': False,
                'error': task_understanding.get('error', 'ä»»åŠ¡ç†è§£å¤±è´¥')
            }

        self.emit_progress(f"ä»»åŠ¡å·²ç†è§£ï¼š{task_understanding['summary']}")

        # ç¬¬äºŒæ­¥ï¼šåˆ¶å®šè®¡åˆ’
        self.emit_progress("æ™ºèƒ½ä½“æ­£åœ¨åˆ¶å®šæ‰§è¡Œè®¡åˆ’...")
        execution_plan = self._create_execution_plan(task_event, task_understanding)
        
        self.emit_progress(f"æ‰§è¡Œè®¡åˆ’å·²åˆ¶å®šï¼Œå…±{len(execution_plan['steps'])}ä¸ªæ­¥éª¤")

        # ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œè®¡åˆ’
        execution_results = []
        for i, step in enumerate(execution_plan['steps'], 1):
            self.emit_progress(f"æ­£åœ¨æ‰§è¡Œæ­¥éª¤ {i}/{len(execution_plan['steps'])}: {step['description']}")
            
            result = self._execute_step(step, task_event, character_context, execution_results)
            execution_results.append(result)
            
            if result.get('needs_user_input'):
                # éœ€è¦ç”¨æˆ·è¾“å…¥
                answer = self.question_tool.ask_user(
                    result['question'],
                    result.get('context', '')
                )
                result['user_answer'] = answer
                self.emit_progress(f"ç”¨æˆ·å·²å›ç­”é—®é¢˜ï¼Œç»§ç»­æ‰§è¡Œ...")

            if not result.get('success'):
                self.emit_progress(f"æ­¥éª¤æ‰§è¡Œå¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return {
                    'success': False,
                    'error': f'æ‰§è¡Œå¤±è´¥äºæ­¥éª¤{i}',
                    'execution_results': execution_results
                }

            self.emit_progress(f"æ­¥éª¤ {i} å®Œæˆ")

        # ç¬¬å››æ­¥ï¼šéªŒè¯ä»»åŠ¡å®Œæˆ
        self.emit_progress("æ‰€æœ‰æ­¥éª¤å·²å®Œæˆï¼Œæ­£åœ¨éªŒè¯ä»»åŠ¡ç»“æœ...")
        
        verification_result = self._verify_task_completion(
            task_event,
            execution_results
        )

        if verification_result['is_completed']:
            self.emit_progress(f"âœ… ä»»åŠ¡éªŒè¯é€šè¿‡ï¼{verification_result['message']}")
            return {
                'success': True,
                'message': 'ä»»åŠ¡å·²æˆåŠŸå®Œæˆ',
                'execution_results': execution_results,
                'verification': verification_result
            }
        else:
            self.emit_progress(f"âš ï¸ ä»»åŠ¡éªŒè¯æœªé€šè¿‡ï¼š{verification_result['message']}")
            return {
                'success': False,
                'error': 'ä»»åŠ¡æœªè¾¾åˆ°å®Œæˆæ ‡å‡†',
                'execution_results': execution_results,
                'verification': verification_result
            }

    def _understand_task(
        self,
        task_event: TaskEvent,
        character_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ç†è§£ä»»åŠ¡è¦æ±‚

        Args:
            task_event: ä»»åŠ¡äº‹ä»¶
            character_context: è§’è‰²ä¸Šä¸‹æ–‡

        Returns:
            ç†è§£ç»“æœ
        """
        debug_logger.log_module('MultiAgentCoordinator', 'å¼€å§‹ç†è§£ä»»åŠ¡')

        # åˆ›å»ºç†è§£æ™ºèƒ½ä½“
        understanding_agent = SubAgent(
            agent_id='understanding_agent',
            role='ä»»åŠ¡åˆ†æä¸“å®¶',
            description='è´Ÿè´£ç†è§£å’Œåˆ†æä»»åŠ¡éœ€æ±‚',
            api_key=self.api_key,
            api_url=self.api_url,
            model_name=self.model_name
        )

        task_description = f"""
ä»»åŠ¡æ ‡é¢˜ï¼š{task_event.title}
ä»»åŠ¡æè¿°ï¼š{task_event.description}
ä»»åŠ¡è¦æ±‚ï¼š{task_event.metadata.get('task_requirements', '')}
å®Œæˆæ ‡å‡†ï¼š{task_event.metadata.get('completion_criteria', '')}
"""

        context = {
            'character': character_context,
            'task_id': task_event.event_id
        }

        result = understanding_agent.execute_task(
            'è¯·åˆ†æè¿™ä¸ªä»»åŠ¡ï¼Œæ€»ç»“ä»»åŠ¡çš„æ ¸å¿ƒç›®æ ‡ã€å…³é”®è¦æ±‚å’Œé¢„æœŸæˆæœã€‚ç”¨ç®€æ´çš„è¯­è¨€æ¦‚æ‹¬ã€‚',
            context
        )

        return {
            'success': True,
            'summary': result,
            'raw_task': task_description
        }

    def _create_execution_plan(
        self,
        task_event: TaskEvent,
        task_understanding: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        åˆ¶å®šæ‰§è¡Œè®¡åˆ’

        Args:
            task_event: ä»»åŠ¡äº‹ä»¶
            task_understanding: ä»»åŠ¡ç†è§£ç»“æœ

        Returns:
            æ‰§è¡Œè®¡åˆ’
        """
        debug_logger.log_module('MultiAgentCoordinator', 'å¼€å§‹åˆ¶å®šæ‰§è¡Œè®¡åˆ’')

        # åˆ›å»ºè§„åˆ’æ™ºèƒ½ä½“
        planning_agent = SubAgent(
            agent_id='planning_agent',
            role='ä»»åŠ¡è§„åˆ’ä¸“å®¶',
            description='è´Ÿè´£å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„æ­¥éª¤',
            api_key=self.api_key,
            api_url=self.api_url,
            model_name=self.model_name
        )

        context = {
            'task_understanding': task_understanding['summary'],
            'task_requirements': task_event.metadata.get('task_requirements', ''),
            'completion_criteria': task_event.metadata.get('completion_criteria', '')
        }

        plan_text = planning_agent.execute_task(
            'è¯·å°†è¿™ä¸ªä»»åŠ¡åˆ†è§£ä¸º3-5ä¸ªå…·ä½“å¯æ‰§è¡Œçš„æ­¥éª¤ã€‚æ¯ä¸ªæ­¥éª¤ç”¨ä¸€è¡Œæè¿°ï¼Œæ ¼å¼ä¸ºï¼šæ­¥éª¤Nï¼šå…·ä½“è¦åšçš„äº‹æƒ…',
            context
        )

        # è§£æè®¡åˆ’æ–‡æœ¬ä¸ºæ­¥éª¤åˆ—è¡¨
        steps = []
        lines = plan_text.strip().split('\n')
        for line in lines:
            line = line.strip()
            if line and ('æ­¥éª¤' in line or line[0].isdigit()):
                # å»é™¤æ­¥éª¤ç¼–å·ï¼Œåªä¿ç•™æè¿°
                if 'ï¼š' in line:
                    description = line.split('ï¼š', 1)[1].strip()
                elif ':' in line:
                    description = line.split(':', 1)[1].strip()
                else:
                    description = line
                
                if description:  # ç¡®ä¿æè¿°ä¸ä¸ºç©º
                    steps.append({
                        'description': description,
                        'status': 'pending'
                    })

        # éªŒè¯è‡³å°‘æœ‰ä¸€ä¸ªæ­¥éª¤
        if not steps:
            debug_logger.log_module('MultiAgentCoordinator', 'è­¦å‘Šï¼šæœªèƒ½ä»è®¡åˆ’ä¸­è§£æå‡ºæœ‰æ•ˆæ­¥éª¤', {
                'plan_text': plan_text
            })
            # åˆ›å»ºä¸€ä¸ªé»˜è®¤æ­¥éª¤
            steps.append({
                'description': 'å®Œæˆä»»åŠ¡è¦æ±‚',
                'status': 'pending'
            })

        return {
            'steps': steps,
            'plan_text': plan_text
        }

    def _execute_step(
        self,
        step: Dict[str, Any],
        task_event: TaskEvent,
        character_context: Dict[str, Any],
        previous_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªæ­¥éª¤

        Args:
            step: æ­¥éª¤ä¿¡æ¯
            task_event: ä»»åŠ¡äº‹ä»¶
            character_context: è§’è‰²ä¸Šä¸‹æ–‡
            previous_results: ä¹‹å‰æ­¥éª¤çš„ç»“æœ

        Returns:
            æ‰§è¡Œç»“æœ
        """
        debug_logger.log_module('MultiAgentCoordinator', 'æ‰§è¡Œæ­¥éª¤', {
            'step': step['description']
        })

        # åˆ›å»ºæ‰§è¡Œæ™ºèƒ½ä½“
        execution_agent = SubAgent(
            agent_id=f'execution_agent_{len(previous_results)}',
            role='ä»»åŠ¡æ‰§è¡Œä¸“å®¶',
            description='è´Ÿè´£æ‰§è¡Œå…·ä½“çš„ä»»åŠ¡æ­¥éª¤',
            api_key=self.api_key,
            api_url=self.api_url,
            model_name=self.model_name
        )

        # å‡†å¤‡å·¥å…·åˆ—è¡¨ï¼ˆåŒ…å«ä¸­æ–­æ€§æé—®å·¥å…·ï¼‰
        tools = [self.question_tool.create_tool_description()]

        context = {
            'character': character_context,
            'task': {
                'title': task_event.title,
                'description': task_event.description
            },
            'previous_results': [r.get('output', '') for r in previous_results]
        }

        result_text = execution_agent.execute_task(
            step['description'],
            context,
            tools
        )

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”¨æˆ·è¾“å…¥
        # æ”¹è¿›çš„æ£€æµ‹é€»è¾‘ï¼šæ£€æŸ¥é—®å·æ˜¯å¦åœ¨å¥å°¾ï¼Œä»¥åŠæ›´å…·ä½“çš„å…³é”®è¯
        needs_input = False
        if isinstance(result_text, str):
            # æ£€æŸ¥å¥å°¾é—®å·
            if result_text.strip().endswith('ï¼Ÿ') or result_text.strip().endswith('?'):
                needs_input = True
            # æ£€æŸ¥ç‰¹å®šçš„æé—®æ¨¡å¼
            elif any(keyword in result_text for keyword in ['éœ€è¦ç¡®è®¤', 'è¯·é—®', 'è¯·æä¾›', 'è¯·è¾“å…¥', 'æ˜¯å¦éœ€è¦']):
                needs_input = True

        return {
            'success': True,
            'step': step['description'],
            'output': result_text,
            'needs_user_input': needs_input,
            'question': result_text if needs_input else None,
            'context': step['description'] if needs_input else None
        }

    def _verify_task_completion(
        self,
        task_event: TaskEvent,
        execution_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        éªŒè¯ä»»åŠ¡æ˜¯å¦å®Œæˆ

        Args:
            task_event: ä»»åŠ¡äº‹ä»¶
            execution_results: æ‰§è¡Œç»“æœåˆ—è¡¨

        Returns:
            éªŒè¯ç»“æœ
        """
        debug_logger.log_module('MultiAgentCoordinator', 'å¼€å§‹éªŒè¯ä»»åŠ¡å®Œæˆæƒ…å†µ')

        # åˆ›å»ºéªŒè¯æ™ºèƒ½ä½“
        verification_agent = SubAgent(
            agent_id='verification_agent',
            role='ä»»åŠ¡éªŒè¯ä¸“å®¶',
            description='è´Ÿè´£éªŒè¯ä»»åŠ¡æ˜¯å¦è¾¾åˆ°å®Œæˆæ ‡å‡†',
            api_key=self.api_key,
            api_url=self.api_url,
            model_name=self.model_name
        )

        # æ•´ç†æ‰§è¡Œç»“æœ
        results_summary = '\n'.join([
            f"æ­¥éª¤{i+1}ï¼š{r['step']}\nç»“æœï¼š{r['output']}"
            for i, r in enumerate(execution_results)
        ])

        context = {
            'task_title': task_event.title,
            'task_description': task_event.description,
            'completion_criteria': task_event.metadata.get('completion_criteria', ''),
            'execution_results': results_summary
        }

        verification_text = verification_agent.execute_task(
            'è¯·æ ¹æ®ä»»åŠ¡çš„å®Œæˆæ ‡å‡†ï¼Œåˆ¤æ–­æ‰§è¡Œç»“æœæ˜¯å¦è¾¾æ ‡ã€‚è¯·ä»¥å¦‚ä¸‹JSONæ ¼å¼å›ç­”ï¼š{"is_completed": true/false, "reason": "åŸå› è¯´æ˜"}ã€‚å¦‚æœæ— æ³•åˆ¤æ–­ï¼Œè¯·åˆç†è¯´æ˜ã€‚',
            context
        )

        # å°è¯•è§£æJSONæ ¼å¼çš„å›å¤
        is_completed = False
        reason = verification_text
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«åœ¨å…¶ä»–æ–‡æœ¬ä¸­ï¼‰
            import re
            json_match = re.search(r'\{[^}]*"is_completed"[^}]*\}', verification_text)
            if json_match:
                verification_json = json.loads(json_match.group(0))
                if isinstance(verification_json, dict) and 'is_completed' in verification_json:
                    is_completed = bool(verification_json['is_completed'])
                    reason = verification_json.get('reason', verification_text)
                else:
                    debug_logger.log_module('MultiAgentCoordinator', f'éªŒè¯æ™ºèƒ½ä½“å›å¤æ ¼å¼ä¸æ­£ç¡®: {verification_text}')
            else:
                # JSONè§£æå¤±è´¥ï¼Œå›é€€åˆ°å…³é”®è¯åŒ¹é…
                debug_logger.log_module('MultiAgentCoordinator', f'æœªæ‰¾åˆ°JSONæ ¼å¼ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…: {verification_text}')
                if 'ã€æ˜¯ã€‘' in verification_text or 'è¾¾æ ‡' in verification_text or 'å·²å®Œæˆ' in verification_text or 'æˆåŠŸå®Œæˆ' in verification_text:
                    is_completed = True
        except Exception as e:
            debug_logger.log_module('MultiAgentCoordinator', f'éªŒè¯æ™ºèƒ½ä½“å›å¤è§£æå¤±è´¥: {e}, å›å¤å†…å®¹: {verification_text}')
            # å›é€€åˆ°åŸæœ‰çš„å…³é”®è¯åŒ¹é…é€»è¾‘
            if 'ã€æ˜¯ã€‘' in verification_text or 'è¾¾æ ‡' in verification_text or 'å·²å®Œæˆ' in verification_text or 'æˆåŠŸå®Œæˆ' in verification_text:
                is_completed = True

        return {
            'is_completed': is_completed,
            'message': reason,
            'execution_summary': results_summary
        }
