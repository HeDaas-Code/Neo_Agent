"""
LangGraphå¯¹è¯æµç¨‹ç®¡ç†æ¨¡å—
ä½¿ç”¨LangGraphå®ç°çŠ¶æ€ç®¡ç†å’Œå¯¹è¯æµç¨‹ç¼–æ’
"""

from typing import TypedDict, Annotated, List, Dict, Any, Optional
import operator
from langgraph.graph import StateGraph, END

from src.tools.debug_logger import get_debug_logger

# è·å–debugæ—¥å¿—è®°å½•å™¨
debug_logger = get_debug_logger()


class ConversationState(TypedDict):
    """
    å¯¹è¯çŠ¶æ€
    å®šä¹‰å¯¹è¯æµç¨‹ä¸­çš„æ‰€æœ‰çŠ¶æ€å˜é‡
    """
    # ç”¨æˆ·è¾“å…¥
    user_input: str
    
    # æ¶ˆæ¯å†å²
    messages: Annotated[List[Dict[str, str]], operator.add]
    
    # ç†è§£é˜¶æ®µçš„ç»“æœ
    understanding: Dict[str, Any]
    
    # çŸ¥è¯†åº“æ£€ç´¢ç»“æœ
    knowledge: Dict[str, Any]
    
    # è§†è§‰ä¸Šä¸‹æ–‡
    vision_context: Optional[Dict[str, Any]]
    
    # æ—¥ç¨‹ä¸Šä¸‹æ–‡
    schedule_context: Optional[str]
    schedule_action: Optional[str]
    
    # NPSå·¥å…·ä¸Šä¸‹æ–‡
    nps_context: Optional[str]
    
    # æ˜¯å¦éœ€è¦æƒ…æ„Ÿåˆ†æ
    need_emotion_analysis: bool
    
    # æƒ…æ„Ÿåˆ†æç»“æœ
    emotion_data: Optional[Dict[str, Any]]
    
    # AIå›å¤
    ai_response: str
    
    # é”™è¯¯ä¿¡æ¯
    error: Optional[str]


class ConversationGraph:
    """
    å¯¹è¯æµç¨‹å›¾
    ä½¿ç”¨LangGraphç¼–æ’å¯¹è¯çš„å„ä¸ªé˜¶æ®µ
    """
    
    def __init__(self, chat_agent):
        """
        åˆå§‹åŒ–å¯¹è¯æµç¨‹å›¾
        
        Args:
            chat_agent: ChatAgentå®ä¾‹ï¼Œæä¾›å„ç§åŠŸèƒ½æ¨¡å—çš„è®¿é—®
        """
        self.agent = chat_agent
        self.graph = self._build_graph()
        
        debug_logger.log_module('ConversationGraph', 'å¯¹è¯æµç¨‹å›¾åˆå§‹åŒ–å®Œæˆ', {})
    
    def _build_graph(self) -> StateGraph:
        """
        æ„å»ºå¯¹è¯æµç¨‹çŠ¶æ€å›¾
        
        Returns:
            StateGraphå®ä¾‹
        """
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(ConversationState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("understand", self._understand_node)
        workflow.add_node("retrieve_knowledge", self._retrieve_knowledge_node)
        workflow.add_node("check_vision", self._check_vision_node)
        workflow.add_node("check_schedule", self._check_schedule_node)
        workflow.add_node("check_nps", self._check_nps_node)
        workflow.add_node("generate_response", self._generate_response_node)
        workflow.add_node("analyze_emotion", self._analyze_emotion_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("understand")
        
        # æ·»åŠ è¾¹ï¼ˆæµç¨‹è·¯å¾„ï¼‰
        workflow.add_edge("understand", "retrieve_knowledge")
        workflow.add_edge("retrieve_knowledge", "check_vision")
        workflow.add_edge("check_vision", "check_schedule")
        workflow.add_edge("check_schedule", "check_nps")
        workflow.add_edge("check_nps", "generate_response")
        
        # æ¡ä»¶è¾¹ï¼šæ˜¯å¦éœ€è¦æƒ…æ„Ÿåˆ†æ
        workflow.add_conditional_edges(
            "generate_response",
            self._should_analyze_emotion,
            {
                "analyze": "analyze_emotion",
                "end": END
            }
        )
        
        workflow.add_edge("analyze_emotion", END)
        
        # ç¼–è¯‘å›¾
        return workflow.compile()
    
    def _understand_node(self, state: ConversationState) -> Dict[str, Any]:
        """
        ç†è§£é˜¶æ®µèŠ‚ç‚¹ï¼šåˆå§‹åŒ–çŠ¶æ€
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ›´æ–°çš„çŠ¶æ€
        """
        debug_logger.log_module('ConversationGraph', 'ç†è§£é˜¶æ®µå¼€å§‹', {
            'input_length': len(state['user_input'])
        })
        
        return {
            "understanding": {
                "stage": "understand",
                "completed": True
            }
        }
    
    def _retrieve_knowledge_node(self, state: ConversationState) -> Dict[str, Any]:
        """
        çŸ¥è¯†æ£€ç´¢èŠ‚ç‚¹ï¼šä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ›´æ–°çš„çŠ¶æ€
        """
        debug_logger.log_module('ConversationGraph', 'çŸ¥è¯†æ£€ç´¢é˜¶æ®µ', {})
        
        # è°ƒç”¨çŸ¥è¯†åº“æ£€ç´¢
        relevant_knowledge = self.agent.memory_manager.knowledge_base.get_relevant_knowledge_for_query(
            state['user_input']
        )
        
        return {
            "knowledge": relevant_knowledge
        }
    
    def _check_vision_node(self, state: ConversationState) -> Dict[str, Any]:
        """
        è§†è§‰æ£€æŸ¥èŠ‚ç‚¹ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦è§†è§‰å·¥å…·
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ›´æ–°çš„çŠ¶æ€
        """
        debug_logger.log_module('ConversationGraph', 'è§†è§‰æ£€æŸ¥é˜¶æ®µ', {})
        
        # æ£€æµ‹ç¯å¢ƒåˆ‡æ¢æ„å›¾
        switch_intent = self.agent.vision_tool.detect_environment_switch_intent(state['user_input'])
        if switch_intent and switch_intent.get('can_switch'):
            from_env = switch_intent['from_env']
            to_env = switch_intent['to_env']
            
            success = self.agent.vision_tool.switch_environment(to_env['uuid'])
            if success:
                switch_msg = f"\nğŸšª [ç¯å¢ƒåˆ‡æ¢] å·²ä»ã€Œ{from_env['name']}ã€ç§»åŠ¨åˆ°ã€Œ{to_env['name']}ã€"
                print(switch_msg)
                self.agent.memory_manager.add_message('system', switch_msg)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨è§†è§‰å·¥å…·
        vision_context = self.agent.vision_tool.get_vision_context(state['user_input'])
        if vision_context:
            vision_summary = self.agent.vision_tool.get_vision_summary(vision_context)
            print(f"\n{vision_summary}")
        
        return {
            "vision_context": vision_context
        }
    
    def _check_schedule_node(self, state: ConversationState) -> Dict[str, Any]:
        """
        æ—¥ç¨‹æ£€æŸ¥èŠ‚ç‚¹ï¼šå¤„ç†æ—¥ç¨‹ç›¸å…³é€»è¾‘
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ›´æ–°çš„çŠ¶æ€
        """
        debug_logger.log_module('ConversationGraph', 'æ—¥ç¨‹æ£€æŸ¥é˜¶æ®µ', {})
        
        schedule_context = None
        schedule_action = None
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ—¥ç¨‹ç›¸å…³çš„é€»è¾‘
        # ä¸ºäº†ä¿æŒç®€æ´ï¼Œæš‚æ—¶è¿”å›ç©ºå€¼
        
        return {
            "schedule_context": schedule_context,
            "schedule_action": schedule_action
        }
    
    def _check_nps_node(self, state: ConversationState) -> Dict[str, Any]:
        """
        NPSå·¥å…·æ£€æŸ¥èŠ‚ç‚¹ï¼šè°ƒç”¨NPSå·¥å…·ç³»ç»Ÿ
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ›´æ–°çš„çŠ¶æ€
        """
        debug_logger.log_module('ConversationGraph', 'NPSå·¥å…·æ£€æŸ¥é˜¶æ®µ', {})
        
        nps_context = None
        nps_result = self.agent.nps_invoker.invoke_relevant_tools(state['user_input'])
        if nps_result['has_context']:
            nps_context = nps_result['context_info']
            invoked_tools = [r['tool_name'] for r in nps_result['tools_invoked'] if r['success']]
            if invoked_tools:
                print(f"\nğŸ”§ [NPSå·¥å…·] å·²è°ƒç”¨: {', '.join(invoked_tools)}")
        
        return {
            "nps_context": nps_context
        }
    
    def _generate_response_node(self, state: ConversationState) -> Dict[str, Any]:
        """
        ç”Ÿæˆå›å¤èŠ‚ç‚¹ï¼šä½¿ç”¨LLMç”Ÿæˆæœ€ç»ˆå›å¤
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ›´æ–°çš„çŠ¶æ€
        """
        debug_logger.log_module('ConversationGraph', 'ç”Ÿæˆå›å¤é˜¶æ®µ', {})
        
        # è¿™é‡Œå°†åœ¨åç»­å®ç°ä¸­è°ƒç”¨LLMç”Ÿæˆå›å¤
        # æš‚æ—¶è¿”å›å ä½ç¬¦
        return {
            "ai_response": "",
            "need_emotion_analysis": False
        }
    
    def _analyze_emotion_node(self, state: ConversationState) -> Dict[str, Any]:
        """
        æƒ…æ„Ÿåˆ†æèŠ‚ç‚¹ï¼šè¿›è¡Œæƒ…æ„Ÿå…³ç³»åˆ†æ
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ›´æ–°çš„çŠ¶æ€
        """
        debug_logger.log_module('ConversationGraph', 'æƒ…æ„Ÿåˆ†æé˜¶æ®µ', {})
        
        emotion_data = self.agent.analyze_emotion()
        
        return {
            "emotion_data": emotion_data
        }
    
    def _should_analyze_emotion(self, state: ConversationState) -> str:
        """
        å†³å®šæ˜¯å¦éœ€è¦è¿›è¡Œæƒ…æ„Ÿåˆ†æ
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            ä¸‹ä¸€æ­¥è¡ŒåŠ¨ ("analyze" æˆ– "end")
        """
        if state.get('need_emotion_analysis', False):
            return "analyze"
        else:
            return "end"
    
    def process(self, user_input: str, messages: List[Dict[str, str]]) -> ConversationState:
        """
        å¤„ç†å¯¹è¯
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            messages: æ¶ˆæ¯å†å²
            
        Returns:
            æœ€ç»ˆçŠ¶æ€
        """
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state: ConversationState = {
            "user_input": user_input,
            "messages": messages,
            "understanding": {},
            "knowledge": {},
            "vision_context": None,
            "schedule_context": None,
            "schedule_action": None,
            "nps_context": None,
            "need_emotion_analysis": False,
            "emotion_data": None,
            "ai_response": "",
            "error": None
        }
        
        # æ‰§è¡Œæµç¨‹å›¾
        try:
            final_state = self.graph.invoke(initial_state)
            return final_state
        except Exception as e:
            debug_logger.log_error('ConversationGraph', f'æµç¨‹æ‰§è¡Œé”™è¯¯: {str(e)}', e)
            return {
                **initial_state,
                "error": str(e),
                "ai_response": f"æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}"
            }
