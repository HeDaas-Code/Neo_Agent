"""
é•¿æ•ˆè®°å¿†ç®¡ç†æ¨¡å—
å®ç°åˆ†å±‚è®°å¿†ç³»ç»Ÿï¼šçŸ­æœŸè®°å¿†ï¼ˆæœ€è¿‘20è½®ï¼‰+ é•¿æœŸæ¦‚æ‹¬è®°å¿† + çŸ¥è¯†åº“
ä½¿ç”¨æ•°æ®åº“æ›¿ä»£JSONæ–‡ä»¶å­˜å‚¨

æ›´æ–°è¯´æ˜:
- é›†æˆMemUæ¡†æ¶ï¼ˆhttps://github.com/NevaMind-AI/memUï¼‰ç”¨äºæ›´é«˜æ•ˆçš„è®°å¿†ç®¡ç†
- å½“MemUå¯ç”¨æ—¶ï¼Œä½¿ç”¨MemUè¿›è¡Œè®°å¿†æ€»ç»“ï¼›å¦åˆ™å›é€€åˆ°ä¼ ç»ŸLLMæ€»ç»“
- çŸ¥è¯†åº“æå–åŠŸèƒ½ä¿æŒä¸å˜
"""

import os
import json
import uuid
from datetime import datetime
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
import requests
from src.core.database_manager import DatabaseManager
from src.core.knowledge_base import KnowledgeBase

# å°è¯•å¯¼å…¥MemUé€‚é…å™¨
try:
    from src.core.memu_memory_adapter import MemUAdapter
    MEMU_ENABLED = True
except ImportError:
    MEMU_ENABLED = False

load_dotenv()


class LongTermMemoryManager:
    """
    é•¿æ•ˆè®°å¿†ç®¡ç†å™¨
    è´Ÿè´£ç®¡ç†çŸ­æœŸè¯¦ç»†è®°å¿†å’Œé•¿æœŸæ¦‚æ‹¬è®°å¿†çš„åˆ†å±‚å­˜å‚¨
    ä½¿ç”¨æ•°æ®åº“æ›¿ä»£JSONæ–‡ä»¶
    """

    def __init__(self,
                 db_manager: DatabaseManager = None,
                 api_key: str = None,
                 api_url: str = None,
                 model_name: str = None):
        """
        åˆå§‹åŒ–é•¿æ•ˆè®°å¿†ç®¡ç†å™¨

        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ï¼ˆå¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°å®ä¾‹ï¼‰
            api_key: APIå¯†é’¥
            api_url: APIåœ°å€
            model_name: æ¨¡å‹åç§°
        """
        # ä½¿ç”¨å…±äº«çš„æ•°æ®åº“ç®¡ç†å™¨
        self.db = db_manager or DatabaseManager()

        # çŸ­æœŸè®°å¿†æœ€å¤§è½®æ•°ï¼ˆä¸€è½® = ä¸€å¯¹user+assistantæ¶ˆæ¯ï¼‰
        self.max_short_term_rounds = 20
        self.max_short_term_messages = self.max_short_term_rounds * 2  # user + assistant

        # çŸ¥è¯†æå–é—´éš”ï¼ˆæ¯5è½®ï¼‰
        self.knowledge_extraction_interval = 5

        # APIé…ç½®ï¼ˆç”¨äºç”Ÿæˆæ¦‚æ‹¬ï¼‰
        self.api_key = api_key or os.getenv('SILICONFLOW_API_KEY')
        self.api_url = api_url or os.getenv('SILICONFLOW_API_URL', 'https://api.siliconflow.cn/v1/chat/completions')
        self.model_name = model_name or os.getenv('MODEL_NAME', 'Qwen/Qwen2.5-7B-Instruct')

        # åˆå§‹åŒ–MemUé€‚é…å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.use_memu = MEMU_ENABLED and os.getenv('USE_MEMU', 'true').lower() == 'true'
        self.memu_adapter = None
        
        if self.use_memu and MEMU_ENABLED:
            try:
                # å°è¯•åˆå§‹åŒ–MemU
                openai_key = os.getenv('OPENAI_API_KEY')
                memu_model = os.getenv('MEMU_MODEL_NAME', 'gpt-4o-mini')
                self.memu_adapter = MemUAdapter(api_key=openai_key, model_name=memu_model)
                print(f"âœ“ MemUè®°å¿†ç®¡ç†å·²å¯ç”¨ï¼ˆæ¨¡å‹: {memu_model}ï¼‰")
            except Exception as e:
                print(f"âš  MemUåˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»ŸLLMæ€»ç»“: {e}")
                self.use_memu = False
        elif not MEMU_ENABLED:
            print("â—‹ MemUæœªå®‰è£…ï¼Œä½¿ç”¨ä¼ ç»ŸLLMæ€»ç»“æ–¹å¼")

        # åˆå§‹åŒ–çŸ¥è¯†åº“ï¼ˆå…±äº«æ•°æ®åº“ç®¡ç†å™¨ï¼‰
        self.knowledge_base = KnowledgeBase(
            db_manager=self.db,
            api_key=self.api_key,
            api_url=self.api_url,
            model_name=self.model_name
        )

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä»JSONè¿ç§»æ•°æ®
        self._check_and_migrate_json()

        print(f"âœ“ é•¿æ•ˆè®°å¿†ç®¡ç†å™¨å·²åˆå§‹åŒ–ï¼ˆä½¿ç”¨æ•°æ®åº“å­˜å‚¨ï¼‰")

    def _check_and_migrate_json(self):
        """æ£€æŸ¥å¹¶è¿ç§»æ—§çš„JSONæ–‡ä»¶"""
        # è¿ç§»çŸ­æœŸè®°å¿†
        short_term_file = os.getenv('MEMORY_FILE', 'memory_data.json')
        if os.path.exists(short_term_file):
            print(f"â—‹ æ£€æµ‹åˆ°æ—§çš„çŸ­æœŸè®°å¿†JSONæ–‡ä»¶ï¼Œæ­£åœ¨è¿ç§»...")
            self.db.migrate_from_json(short_term_file, 'short_term')
            os.rename(short_term_file, short_term_file + '.bak')
            print(f"âœ“ çŸ­æœŸè®°å¿†å·²è¿ç§»ï¼ŒJSONæ–‡ä»¶å·²å¤‡ä»½")

        # è¿ç§»é•¿æœŸè®°å¿†
        long_term_file = 'longmemory_data.json'
        if os.path.exists(long_term_file):
            print(f"â—‹ æ£€æµ‹åˆ°æ—§çš„é•¿æœŸè®°å¿†JSONæ–‡ä»¶ï¼Œæ­£åœ¨è¿ç§»...")
            self.db.migrate_from_json(long_term_file, 'long_term')
            os.rename(long_term_file, long_term_file + '.bak')
            print(f"âœ“ é•¿æœŸè®°å¿†å·²è¿ç§»ï¼ŒJSONæ–‡ä»¶å·²å¤‡ä»½")

    def add_message(self, role: str, content: str):
        """
        æ·»åŠ æ–°æ¶ˆæ¯åˆ°çŸ­æœŸè®°å¿†ï¼ˆä½¿ç”¨æ•°æ®åº“ï¼‰

        Args:
            role: è§’è‰²ç±»å‹ ('user' æˆ– 'assistant')
            content: æ¶ˆæ¯å†…å®¹
        """
        # æ·»åŠ åˆ°æ•°æ®åº“
        self.db.add_short_term_message(role, content)

        # æ›´æ–°å…ƒæ•°æ®
        if role == 'user':
            total_conversations = self.db.get_metadata('total_conversations', 0)
            total_conversations += 1
            self.db.set_metadata('total_conversations', total_conversations)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦æå–çŸ¥è¯†ï¼ˆæ¯5è½®ï¼‰
            if total_conversations % self.knowledge_extraction_interval == 0:
                print(f"\nğŸ“š å·²è¾¾åˆ° {total_conversations} è½®å¯¹è¯ï¼Œå¼€å§‹æå–çŸ¥è¯†...")
                self._extract_and_save_knowledge()

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å½’æ¡£
        self._check_and_archive()

    def _check_and_archive(self):
        """
        æ£€æŸ¥çŸ­æœŸè®°å¿†æ˜¯å¦è¶…è¿‡é™åˆ¶ï¼Œå¦‚æœè¶…è¿‡åˆ™å½’æ¡£æ—§è®°å¿†
        """
        # è·å–æ‰€æœ‰çŸ­æœŸè®°å¿†
        messages = self.db.get_short_term_messages()

        # è®¡ç®—å½“å‰å¯¹è¯è½®æ•°
        user_count = sum(1 for msg in messages if msg['role'] == 'user')

        # å¦‚æœè¶…è¿‡20è½®ï¼Œå°†æœ€æ—©çš„20è½®å½’æ¡£
        if user_count > self.max_short_term_rounds:
            print(f"\nâš  çŸ­æœŸè®°å¿†å·²è¾¾ {user_count} è½®ï¼Œå¼€å§‹å½’æ¡£...")
            self._archive_old_messages()

    def _archive_old_messages(self):
        """
        å°†æœ€æ—©çš„20è½®å¯¹è¯å½’æ¡£ä¸ºæ¦‚æ‹¬è®°å¿†
        """
        # è·å–æ‰€æœ‰çŸ­æœŸè®°å¿†æ¶ˆæ¯
        all_messages = self.db.get_short_term_messages()

        # æ‰¾å‡ºå‰20è½®å¯¹è¯ï¼ˆ40æ¡æ¶ˆæ¯ï¼‰
        messages_to_archive = []
        message_ids_to_delete = []
        user_count = 0

        for msg in all_messages:
            messages_to_archive.append(msg)
            message_ids_to_delete.append(msg['id'])
            if msg['role'] == 'user':
                user_count += 1
                if user_count >= self.max_short_term_rounds:
                    break

        # ç”Ÿæˆæ¦‚æ‹¬
        summary = self._generate_summary(messages_to_archive)

        if summary:
            # ä¿å­˜åˆ°é•¿æœŸè®°å¿†ï¼ˆæ•°æ®åº“ï¼‰
            self.db.add_long_term_summary(
                summary=summary,
                rounds=user_count,
                message_count=len(messages_to_archive),
                created_at=messages_to_archive[0]['timestamp'] if messages_to_archive else datetime.now().isoformat(),
                ended_at=messages_to_archive[-1]['timestamp'] if messages_to_archive else datetime.now().isoformat()
            )

            # ä»çŸ­æœŸè®°å¿†ä¸­ç§»é™¤å·²å½’æ¡£çš„æ¶ˆæ¯
            self.db.delete_short_term_messages(message_ids_to_delete)

            print(f"âœ“ å·²å½’æ¡£ {user_count} è½®å¯¹è¯ï¼ˆ{len(messages_to_archive)} æ¡æ¶ˆæ¯ï¼‰")
            print(f"âœ“ ç”Ÿæˆä¸»é¢˜æ¦‚æ‹¬: {summary[:50]}...")

    def _extract_and_save_knowledge(self):
        """
        ä»æœ€è¿‘5è½®å¯¹è¯ä¸­æå–å¹¶ä¿å­˜çŸ¥è¯†
        åŒæ—¶å®šæœŸæ¸…ç†è¿‡æ—¶çš„çŸ¥è¯†
        """
        # ä»æ•°æ®åº“è·å–æ‰€æœ‰çŸ­æœŸè®°å¿†
        all_messages = self.db.get_short_term_messages()

        # è·å–æœ€è¿‘5è½®å¯¹è¯ï¼ˆ10æ¡æ¶ˆæ¯ï¼‰
        recent_messages = []
        user_count = 0

        for msg in reversed(all_messages):
            recent_messages.insert(0, msg)
            if msg['role'] == 'user':
                user_count += 1
                if user_count >= 5:
                    break

        if len(recent_messages) < 2:  # è‡³å°‘éœ€è¦ä¸€è½®å¯¹è¯
            print("âœ— æ¶ˆæ¯å¤ªå°‘ï¼Œæ— æ³•æå–çŸ¥è¯†")
            return

        # ä½¿ç”¨çŸ¥è¯†åº“æå–çŸ¥è¯†
        knowledge_list = self.knowledge_base.extract_knowledge(recent_messages)

        if knowledge_list and len(knowledge_list) > 0:
            print(f"âœ“ æå–åˆ° {len(knowledge_list)} æ¡çŸ¥è¯†")

            # ä¿å­˜æ¯æ¡çŸ¥è¯†
            for knowledge_data in knowledge_list:
                entity_name = knowledge_data.get('entity_name', knowledge_data.get('title', 'æœªçŸ¥'))
                is_def = knowledge_data.get('is_definition', False)
                content = knowledge_data.get('content', '')
                content_preview = content[:30]
                print(f"  â€¢ [{knowledge_data.get('type', 'å…¶ä»–')}] {entity_name}{'çš„å®šä¹‰' if is_def else ''}: {content_preview}...")

                # ä¿å­˜åˆ°æ•°æ®åº“
                entity_uuid = self.db.find_or_create_entity(entity_name)

                if is_def:
                    # ä¿å­˜ä¸ºå®šä¹‰
                    self.db.set_entity_definition(
                        entity_uuid=entity_uuid,
                        content=content,
                        type_=knowledge_data.get('type', 'å®šä¹‰'),
                        source=knowledge_data.get('source', 'å¯¹è¯æå–'),
                        confidence=knowledge_data.get('confidence', 0.8)
                    )
                    print(f"    ç½®ä¿¡åº¦: {knowledge_data.get('confidence', 0.8):.2f} | å®ä½“UUID: {entity_uuid}")
                else:
                    # ä¿å­˜ä¸ºç›¸å…³ä¿¡æ¯ï¼Œé»˜è®¤çŠ¶æ€ä¸º"ç–‘ä¼¼"
                    # add_entity_related_info ä¼šæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒä¿¡æ¯ï¼Œå¦‚æœå­˜åœ¨ä¼šå¢åŠ mention_count
                    from src.core.database_manager import DatabaseManager
                    info_uuid = self.db.add_entity_related_info(
                        entity_uuid=entity_uuid,
                        content=content,
                        type_=knowledge_data.get('type', 'å…¶ä»–'),
                        source=knowledge_data.get('source', 'å¯¹è¯æå–'),
                        confidence=knowledge_data.get('confidence', 0.7),
                        status=DatabaseManager.STATUS_SUSPECTED
                    )
                    
                    # è·å–ä¿¡æ¯çŠ¶æ€ä»¥æ˜¾ç¤º
                    info = self.db.get_entity_related_info(entity_uuid)
                    saved_info = next((i for i in info if i['uuid'] == info_uuid), None)
                    if saved_info:
                        status = saved_info.get('status', DatabaseManager.STATUS_SUSPECTED)
                        mention_count = saved_info.get('mention_count', 1)
                        status_label = f"[{status}]" if status == DatabaseManager.STATUS_CONFIRMED else f"[{status}Ã—{mention_count}]"
                        print(f"    çŠ¶æ€: {status_label} | ç½®ä¿¡åº¦: {knowledge_data.get('confidence', 0.7):.2f} | å®ä½“UUID: {entity_uuid}")
                    else:
                        print(f"    ç½®ä¿¡åº¦: {knowledge_data.get('confidence', 0.7):.2f} | å®ä½“UUID: {entity_uuid}")

            # æ¯æ¬¡æå–çŸ¥è¯†åï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†è¿‡æ—¶ä¿¡æ¯
            # æ¯10æ¬¡æå–æ¸…ç†ä¸€æ¬¡ï¼ˆå³æ¯50è½®å¯¹è¯ï¼‰
            total_conv = self.db.get_metadata('total_conversations', 0)
            if total_conv % 50 == 0 and total_conv > 0:
                print("â—‹ æ‰§è¡Œå®šæœŸçŸ¥è¯†åº“æ¸…ç†...")
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ¸…ç†é€»è¾‘
                print(f"âœ“ æ¸…ç†å®Œæˆ")
        else:
            print("â—‹ æœªæå–åˆ°æ–°çŸ¥è¯†")

    def _generate_summary(self, messages: List[Dict[str, Any]]) -> Optional[str]:
        """
        ç”Ÿæˆå¯¹è¯æ¦‚æ‹¬
        
        ä¼˜å…ˆä½¿ç”¨MemUè¿›è¡Œè®°å¿†ç®¡ç†å’Œæ€»ç»“ï¼Œå¦‚æœMemUä¸å¯ç”¨åˆ™å›é€€åˆ°ä¼ ç»ŸLLMæ€»ç»“

        Args:
            messages: è¦æ¦‚æ‹¬çš„æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ¦‚æ‹¬æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        # é¦–å…ˆå°è¯•ä½¿ç”¨MemU
        if self.use_memu and self.memu_adapter:
            try:
                print("â—‹ ä½¿ç”¨MemUç”Ÿæˆå¯¹è¯æ¦‚æ‹¬...")
                summary = self.memu_adapter.generate_summary(messages)
                if summary:
                    print(f"âœ“ MemUç”Ÿæˆæ¦‚æ‹¬æˆåŠŸ")
                    return summary
                else:
                    print("âš  MemUæœªè¿”å›æ¦‚æ‹¬ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹å¼")
            except Exception as e:
                print(f"âš  MemUç”Ÿæˆæ¦‚æ‹¬å¤±è´¥: {e}ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹å¼")
        
        # å›é€€åˆ°ä¼ ç»ŸLLMæ€»ç»“æ–¹å¼
        try:
            # æ„å»ºå¯¹è¯æ–‡æœ¬
            conversation_text = ""
            for msg in messages:
                role_name = "ç”¨æˆ·" if msg['role'] == 'user' else "åŠ©æ‰‹"
                conversation_text += f"{role_name}: {msg['content']}\n"

            # æ„å»ºæ¦‚æ‹¬è¯·æ±‚
            summary_prompt = f"""è¯·å¯¹ä»¥ä¸‹å¯¹è¯è¿›è¡Œä¸»é¢˜æ¦‚æ‹¬ï¼Œè¦æ±‚ï¼š
1. ç”¨ä¸€å¥è¯æ€»ç»“å¯¹è¯çš„ä¸»è¦ä¸»é¢˜å’Œå†…å®¹
2. æç‚¼å…³é”®ä¿¡æ¯å’Œè®¨è®ºè¦ç‚¹
3. ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡100å­—
4. åªè¿”å›æ¦‚æ‹¬å†…å®¹ï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜

å¯¹è¯å†…å®¹ï¼š
{conversation_text}

è¯·ç»™å‡ºä¸»é¢˜æ¦‚æ‹¬ï¼š"""

            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }

            payload = {
                'model': self.model_name,
                'messages': [
                    {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è¯åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æ€»ç»“å¯¹è¯ä¸»é¢˜ã€‚'},
                    {'role': 'user', 'content': summary_prompt}
                ],
                'temperature': 0.3,  # ä½¿ç”¨è¾ƒä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„æ¦‚æ‹¬
                'max_tokens': 200,
                'stream': False
            }

            response = requests.post(
                self.api_url,
                headers=headers,
                json=payload,
                timeout=30
            )

            response.raise_for_status()
            result = response.json()

            if 'choices' in result and len(result['choices']) > 0:
                summary = result['choices'][0]['message']['content'].strip()
                return summary
            else:
                print("âœ— æœªèƒ½è·å–æœ‰æ•ˆçš„æ¦‚æ‹¬ç»“æœ")
                return None

        except Exception as e:
            print(f"âœ— ç”Ÿæˆæ¦‚æ‹¬æ—¶å‡ºé”™: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤æ¦‚æ‹¬
            return f"å¯¹è¯è®°å½• ({len(messages)} æ¡æ¶ˆæ¯)"

    def get_recent_messages(self, count: int = 10) -> List[Dict[str, str]]:
        """
        è·å–æœ€è¿‘çš„Næ¡çŸ­æœŸè®°å¿†æ¶ˆæ¯ï¼ˆä»æ•°æ®åº“ï¼‰

        Args:
            count: è¦è·å–çš„æ¶ˆæ¯æ•°é‡

        Returns:
            æ¶ˆæ¯åˆ—è¡¨
        """
        messages = self.db.get_short_term_messages(limit=count)
        return [{'role': msg['role'], 'content': msg['content']} for msg in messages]

    def get_all_summaries(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰é•¿æœŸè®°å¿†æ¦‚æ‹¬ï¼ˆä»æ•°æ®åº“ï¼‰

        Returns:
            æ¦‚æ‹¬åˆ—è¡¨
        """
        return self.db.get_long_term_summaries()
    
    def get_long_term_summaries(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        è·å–é•¿æœŸè®°å¿†æ¦‚æ‹¬ï¼ˆæ”¯æŒé™åˆ¶æ•°é‡ï¼‰

        Args:
            limit: é™åˆ¶è¿”å›çš„æ¦‚æ‹¬æ•°é‡ï¼ŒNoneè¡¨ç¤ºè¿”å›å…¨éƒ¨

        Returns:
            æ¦‚æ‹¬åˆ—è¡¨
        """
        summaries = self.db.get_long_term_summaries()
        if limit is not None and limit > 0:
            return summaries[:limit]
        return summaries

    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯ï¼ˆä»æ•°æ®åº“ï¼‰

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        # ä»æ•°æ®åº“è·å–æ¶ˆæ¯
        short_term_messages = self.db.get_short_term_messages()
        long_term_summaries = self.db.get_long_term_summaries()

        short_user = sum(1 for msg in short_term_messages if msg['role'] == 'user')
        short_assistant = sum(1 for msg in short_term_messages if msg['role'] == 'assistant')

        # è·å–çŸ¥è¯†åº“ç»Ÿè®¡
        db_stats = self.db.get_statistics()

        # è·å–çŸ¥è¯†åº“è¯¦ç»†ç»Ÿè®¡
        kb_stats = self.knowledge_base.get_statistics()

        return {
            'short_term': {
                'total_messages': len(short_term_messages),
                'user_messages': short_user,
                'assistant_messages': short_assistant,
                'rounds': short_user
            },
            'long_term': {
                'total_summaries': len(long_term_summaries),
                'total_archived_rounds': sum(s.get('rounds', 0) for s in long_term_summaries),
                'total_archived_messages': sum(s.get('message_count', 0) for s in long_term_summaries)
            },
            'knowledge_base': {
                'total_entities': db_stats['entities_count'],
                'total_base_knowledge': db_stats['base_knowledge_count'],
                'total_knowledge': kb_stats['total_knowledge'],  # æ·»åŠ æ€»çŸ¥è¯†æ•°ä»¥ä¿æŒå…¼å®¹æ€§
                'total_definitions': kb_stats['total_definitions'],
                'total_related_info': kb_stats['total_related_info']
            },
            'total_conversations': self.db.get_metadata('total_conversations', 0),
            'database_size_kb': db_stats.get('db_size_kb', 0)
        }

    def clear_all_memory(self):
        """
        æ¸…ç©ºæ‰€æœ‰è®°å¿†ï¼ˆçŸ­æœŸã€é•¿æœŸï¼‰
        """
        self.db.clear_short_term_memory()
        self.db.clear_long_term_memory()
        self.db.set_metadata('total_conversations', 0)
        print("âœ“ æ‰€æœ‰è®°å¿†å·²æ¸…ç©º")

    def get_context_for_chat(self, recent_count: int = 10) -> str:
        """
        è·å–ç”¨äºèŠå¤©çš„ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«é•¿æœŸè®°å¿†æ¦‚æ‹¬å’ŒçŸ­æœŸè®°å¿†ï¼‰

        Args:
            recent_count: æœ€è¿‘æ¶ˆæ¯æ•°é‡

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        context_parts = []

        # æ·»åŠ é•¿æœŸè®°å¿†æ¦‚æ‹¬ï¼ˆå¦‚æœæœ‰ï¼‰
        long_term_summaries = self.db.get_long_term_summaries()
        if long_term_summaries:
            context_parts.append("ã€å†å²å¯¹è¯ä¸»é¢˜å›é¡¾ã€‘")
            for i, summary in enumerate(long_term_summaries[-5:], 1):  # åªå–æœ€è¿‘5ä¸ªæ¦‚æ‹¬
                context_parts.append(f"{i}. {summary['summary']}")
            context_parts.append("")

        return "\n".join(context_parts) if context_parts else ""


if __name__ == '__main__':
    print("=" * 60)
    print("é•¿æ•ˆè®°å¿†ç®¡ç†å™¨æµ‹è¯•")
    print("=" * 60)

    manager = LongTermMemoryManager()

    print("\nå½“å‰è®°å¿†ç»Ÿè®¡:")
    stats = manager.get_statistics()
    print(f"çŸ­æœŸè®°å¿†: {stats['short_term']['rounds']} è½®å¯¹è¯ ({stats['short_term']['total_messages']} æ¡æ¶ˆæ¯)")
    print(f"é•¿æœŸè®°å¿†: {stats['long_term']['total_summaries']} ä¸ªä¸»é¢˜æ¦‚æ‹¬")
    print(f"çŸ¥è¯†åº“å®ä½“: {stats['knowledge_base']['total_entities']} ä¸ª")
    print(f"æ€»å¯¹è¯è½®æ•°: {stats['total_conversations']} è½®")
    print(f"æ•°æ®åº“å¤§å°: {stats['database_size_kb']:.2f} KB")

    long_term_summaries = manager.get_all_summaries()
    if long_term_summaries:
        print("\né•¿æœŸè®°å¿†æ¦‚æ‹¬:")
        for i, summary in enumerate(long_term_summaries, 1):
            print(f"{i}. [{summary['created_at'][:10]}] {summary['summary']}")
    else:
        print("\næš‚æ— é•¿æœŸè®°å¿†æ¦‚æ‹¬")

    print("\nâœ“ æµ‹è¯•å®Œæˆ")
